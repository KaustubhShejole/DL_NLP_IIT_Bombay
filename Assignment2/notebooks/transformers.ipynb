{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRdpoWePeYHn"
   },
   "source": [
    "## Importing Libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0LBvFtYGCNgJ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 18 06:00:06 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   59C    P0             105W / 300W |  15603MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              70W / 300W |    827MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   57C    P0              77W / 300W |   2850MiB / 81920MiB |     15%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              59W / 300W |    663MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z4ZVrIumZcDt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1760767210.903159] [bfd74565809f:5601 :f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import wandb\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwL09v65CIse",
    "outputId": "5ea72523-6a50-474c-b617-b77e16d72ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44xIRolL_T_d"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y4zemXiyE6Fi"
   },
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {'#': 0, '$': 1, '^': 2}   # '^': start of sequence, '$' : unknown char, '#' : padding\n",
    "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
    "        self.vocab_size = 3  # Count\n",
    "\n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.vocab_size\n",
    "            self.index2char[self.vocab_size] = char\n",
    "            self.vocab_size += 1\n",
    "\n",
    "    def encode(self, s):\n",
    "        return [self.char2index[ch] for ch in s]\n",
    "\n",
    "    def decode(self, l):\n",
    "        return ''.join([self.index2char[i] for i in l])\n",
    "\n",
    "    def vocab(self):\n",
    "        return self.char2index.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns maximum length of input and output words\n",
    "def maxLength(data):\n",
    "    ip_mlen, op_mlen = 0, 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        input = data[0][i]\n",
    "        output = data[1][i]\n",
    "        if(len(input)>ip_mlen):\n",
    "            ip_mlen=len(input)\n",
    "\n",
    "        if(len(output)>op_mlen):\n",
    "            op_mlen=len(output)\n",
    "\n",
    "    return ip_mlen, op_mlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getMaxLengthValues(lang):\n",
    "    base_path = f\"../../aks_dataset/{lang}\"\n",
    "    \n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(f\"{base_path}/train.csv\", header=None)\n",
    "    val_df = pd.read_csv(f\"{base_path}/valid.csv\", header=None)\n",
    "    test_df = pd.read_csv(f\"{base_path}/test.csv\", header=None)\n",
    "\n",
    "    # Initialize language vocabularies\n",
    "    input_lang = Language('eng')\n",
    "    output_lang = Language(lang)\n",
    "    \n",
    "    # Build vocabulary only from train data\n",
    "    for _, row in train_df.iterrows():\n",
    "        input_lang.addWord(str(row[0]))\n",
    "        output_lang.addWord(str(row[1]))\n",
    "    \n",
    "    # Compute max input/output lengths for each split\n",
    "    m1, m01 = maxLength(train_df)\n",
    "    m2, m02 = maxLength(test_df)\n",
    "    m3, m03 = maxLength(val_df)\n",
    "\n",
    "    # Return the largest values across all splits\n",
    "    return max(m1, m2, m3), max(m01, m02, m03)\n",
    "\n",
    "# Example usage\n",
    "input_max_len, output_max_len = getMaxLengthValues('hin')\n",
    "print(input_max_len, output_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IDGaCO8DkYpc"
   },
   "outputs": [],
   "source": [
    "input_shape = 0\n",
    "def preprocess(data, input_lang, output_lang, input_max_len, output_max_len, s=''):\n",
    "\n",
    "    unknown = input_lang.char2index['$']\n",
    "\n",
    "    n = len(data)\n",
    "    input = torch.zeros((n, input_max_len + 1), device = device)\n",
    "    output = torch.zeros((n, output_max_len + 2), device = device)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        inp = data[0][i].ljust(input_max_len + 1, '#')\n",
    "        op = '^' + data[1][i]       # add start symbol to output\n",
    "        op = op.ljust(output_max_len + 2, '#')\n",
    "\n",
    "        for index, char in enumerate(inp):\n",
    "            if char in input_lang.char2index:\n",
    "                input[i][index] = input_lang.char2index[char]\n",
    "            else:\n",
    "                input[i][index] = unknown\n",
    "\n",
    "        for index, char in enumerate(op):\n",
    "            if char in output_lang.char2index:\n",
    "                output[i][index] = output_lang.char2index[char]\n",
    "            else:\n",
    "                output[i][index] = unknown\n",
    "\n",
    "    print(s, ' dataset')\n",
    "    print(input.shape)\n",
    "    print(output.shape)\n",
    "\n",
    "    return TensorDataset(input.to(torch.int32), output.to(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdS5OXKxfdCX",
    "outputId": "283fb51a-9a4a-4fc5-bad1-ea66373b29b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  dataset\n",
      "torch.Size([100000, 30])\n",
      "torch.Size([100000, 28])\n",
      "validation  dataset\n",
      "torch.Size([6357, 30])\n",
      "torch.Size([6357, 28])\n",
      "test  dataset\n",
      "torch.Size([10112, 30])\n",
      "torch.Size([10112, 28])\n"
     ]
    }
   ],
   "source": [
    "def load_prepare_data(lang):\n",
    "    train_df = pd.read_csv(f\"../../aks_dataset/{lang}/train.csv\", header = None)\n",
    "    val_df = pd.read_csv(f\"../../aks_dataset/{lang}/valid.csv\", header = None)\n",
    "    test_df = pd.read_csv(f\"../../aks_dataset/{lang}/test.csv\", header = None)\n",
    "\n",
    "    input_lang = Language('eng')\n",
    "    output_lang = Language(lang)\n",
    "\n",
    "    # create vocablury\n",
    "    for i in range(len(train_df)):\n",
    "        input_lang.addWord(train_df[0][i]) # 'eng'\n",
    "        output_lang.addWord(train_df[1][i]) # 'hin'\n",
    "\n",
    "    # encode the datasets\n",
    "    train_data = preprocess(train_df, input_lang, output_lang,input_max_len, output_max_len, 'train')\n",
    "    val_data = preprocess(val_df, input_lang, output_lang,input_max_len, output_max_len, 'validation')\n",
    "    test_data = preprocess(test_df, input_lang, output_lang,input_max_len, output_max_len, 'test')\n",
    "\n",
    "    return train_data, val_data, test_data, input_lang, output_lang\n",
    "\n",
    "\n",
    "train_data, val_data, test_data, input_lang, output_lang = load_prepare_data('hin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nu-NTR6BDj8e",
    "outputId": "bd3dba2a-092d-4846-a5fb-f703f119b56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urjapurna#####################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'^उर्जापूर्ण#################'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_lang.decode(train_data[23][0].tolist()))\n",
    "output_lang.decode(train_data[23][1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJI8iU6dBSE0",
    "outputId": "818815ee-503e-4dcd-b7a6-5f00a06b5ace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 42, 15, 18,  8, 12,  3, 29, 15, 18, 43,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[23][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api_key.txt') as input_file:\n",
    "    key = input_file.read()\n",
    "key = key.split('\\n')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvmzS5Lt_Jnl",
    "outputId": "1387d646-ea3c-4fbf-b44f-c071e2b07784"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msshejole132\u001b[0m (\u001b[33msshejole132-iit-bombay\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key =key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1TioafYgICa"
   },
   "source": [
    "# seq2seq tranformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K94_u35dCk7-"
   },
   "source": [
    "### hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PugX7KHvc65u"
   },
   "outputs": [],
   "source": [
    "n_embd = 64\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "n_head = 4 # other options factors of 32 like 2, 8\n",
    "n_layers = 2\n",
    "dropout = 0.2\n",
    "epochs = 50\n",
    "\n",
    "# encoder specific detail\n",
    "input_vocab_size = input_lang.vocab_size\n",
    "encoder_block_size = len(train_data[0][0])\n",
    "\n",
    "# decoder specific detail\n",
    "output_vocab_size = output_lang.vocab_size\n",
    "decoder_block_size = len(train_data[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdltQ7oJCq1j"
   },
   "source": [
    "### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uiluDiY7FAMU"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one self-attention head \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, d_k, dropout, mask=0): # d_k is dimention of key , nomaly d_k = n_embd / 4\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.key = nn.Linear(n_embd, d_k, bias=False, device=device)\n",
    "        self.query = nn.Linear(n_embd, d_k, bias=False, device=device)\n",
    "        self.value = nn.Linear(n_embd, d_k, bias=False, device=device)\n",
    "        if mask:\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(encoder_block_size, encoder_block_size, device=device)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output = None):\n",
    "        B,T,C = x.shape\n",
    "\n",
    "        if encoder_output is not None:\n",
    "            k = self.key(encoder_output)\n",
    "            Be, Te, Ce = encoder_output.shape\n",
    "        else:\n",
    "            k = self.key(x) # (B,T,d_k)\n",
    "\n",
    "        q = self.query(x) # (B,T,d_k)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B,T,T)\n",
    "\n",
    "        if self.mask:\n",
    "            if encoder_output is not None:\n",
    "                wei = wei.masked_fill(self.tril[:T, :Te] == 0, float('-inf')) # (B,T,T)\n",
    "            else:\n",
    "                wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B,T,T)\n",
    "\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform weighted aggregation of values\n",
    "        if encoder_output is not None:\n",
    "            v = self.value(encoder_output)\n",
    "        else:\n",
    "            v = self.value(x)\n",
    "        out = wei @ v # (B,T,C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple self attention heads in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, num_head, d_k, dropout, mask=0):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(n_embd, d_k, dropout, mask) for _ in range(num_head)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output=None):\n",
    "        out = torch.cat([h(x, encoder_output) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" multiple self attention heads in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class encoderBlock(nn.Module):\n",
    "    \"\"\" Tranformer encoder block : communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, dropout):\n",
    "        super().__init__()\n",
    "        d_k = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_embd, n_head, d_k, dropout)\n",
    "        self.ffwd = FeedForward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x, encoder_output=None):\n",
    "        x = x + self.sa(self.ln1(x), encoder_output)\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(input_vocab_size, n_embd) # n_embd: input embedding dimension\n",
    "        self.position_embedding_table = nn.Embedding(encoder_block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[encoderBlock(n_embd, n_head, dropout) for _ in range(n_layers)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,n_embd)\n",
    "        x = tok_emb + pos_emb # (B,T,n_embd)\n",
    "        x = self.blocks(x) # apply one attention layer (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgPU486JC8Mz"
   },
   "source": [
    "### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JteOV0CdC_bv"
   },
   "outputs": [],
   "source": [
    "class decoderBlock(nn.Module):\n",
    "    \"\"\" Tranformer decoder block : self communication then cross communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, dropout):\n",
    "        super().__init__()\n",
    "        d_k = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_embd, n_head, d_k, dropout, mask = 1)\n",
    "        self.ca = MultiHeadAttention(n_embd, n_head, d_k, dropout, mask = 1)\n",
    "        self.ffwd = FeedForward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd, device=device)\n",
    "        self.ln2 = nn.LayerNorm(n_embd, device=device)\n",
    "        self.ln3 = nn.LayerNorm(n_embd, device=device)\n",
    "\n",
    "    def forward(self, x_encoder_output):\n",
    "        x = x_encoder_output[0]\n",
    "        encoder_output = x_encoder_output[1]\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ca(self.ln2(x), encoder_output)\n",
    "        x = x + self.ffwd(self.ln3(x))\n",
    "        return (x,encoder_output)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(output_vocab_size, n_embd) # n_embd: input embedding dimension\n",
    "        self.position_embedding_table = nn.Embedding(decoder_block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[decoderBlock(n_embd, n_head=n_head, dropout=dropout) for _ in range(n_layers)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, output_vocab_size)\n",
    "\n",
    "    def forward(self, idx, encoder_output, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,n_embd)\n",
    "        x = tok_emb + pos_emb # (B,T,n_embd)\n",
    "\n",
    "        x =self.blocks((x, encoder_output))\n",
    "        x = self.ln_f(x[0]) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,output_vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            temp_logits = logits.view(B*T, C)\n",
    "            targets = targets.reshape(B*T)\n",
    "\n",
    "            loss = F.cross_entropy(temp_logits, targets.long())\n",
    "\n",
    "        # print(logits)\n",
    "        # out = torch.argmax(logits)\n",
    "\n",
    "        return logits, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBjmsIcklM8Y"
   },
   "source": [
    "# Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLfHEDk8FNfY"
   },
   "source": [
    "## sweep config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nDcRZmb80msE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: olbj21xb\n",
      "Sweep URL: https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb\n"
     ]
    }
   ],
   "source": [
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"name\": \"sweep\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"val_acc\"},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [64, 128, 256]},\n",
    "        \"epochs\": {\"values\": [20, 40, 50, 100]},\n",
    "        \"lr\": {\"max\": 0.1, \"min\": 0.0001},\n",
    "        \"n_embd\": {\"values\": [16, 32, 64]},\n",
    "        \"n_head\": {\"values\": [2, 4, 8]},\n",
    "        \"n_layers\": {\"values\": [2]},\n",
    "        \"dropout\": {\"values\": [0, .1, .2, .3]}\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"Tranliteration-Tranformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9CguGUG5_1NL"
   },
   "outputs": [],
   "source": [
    "# wandb.sweep_cancel(sweep_id)\n",
    "# wandb.finish()\n",
    "# wandb.run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5T58TQRECbZ"
   },
   "source": [
    "## train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3GWnCggNFLs3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train():\n",
    "    run = wandb.init()\n",
    "\n",
    "    n_embd = wandb.config.n_embd\n",
    "    n_head = wandb.config.n_head\n",
    "    n_layers = wandb.config.n_layers\n",
    "    dropout = wandb.config.dropout\n",
    "    epochs = wandb.config.epochs\n",
    "    batch_size = wandb.config.batch_size\n",
    "    learning_rate = wandb.config.lr\n",
    "\n",
    "\n",
    "    encoder = Encoder(n_embd, n_head, n_layers, dropout)\n",
    "    decoder = Decoder(n_embd, n_head, n_layers, dropout)\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
    "\n",
    "    # print the number of parameters in the model\n",
    "    print(sum([p.numel() for p in encoder.parameters()] + [p.numel() for p in decoder.parameters()])/1e3, 'K model parameters')\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # create a PyTorch optimizer\n",
    "    encoder_optimizer = torch.optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('Step | Training Loss | Validation Loss   |   Training Accuracy %  |  Validation Accuracy %')\n",
    "\n",
    "    least_error = float('inf')\n",
    "    patience = 20  # The number of epochs without improvement to wait before stopping\n",
    "    no_improvement = 0\n",
    "\n",
    "    for i in tqdm(range(epochs)):\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        for j,(train_x,train_y) in enumerate(train_loader):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "\n",
    "            encoder_optimizer.zero_grad(set_to_none=True)\n",
    "            decoder_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            encoder_output = encoder(train_x)\n",
    "            logits, loss = decoder(train_y[:, :-1], encoder_output, train_y[:, 1:])\n",
    "\n",
    "            encoder_optimizer.zero_grad(set_to_none=True)\n",
    "            decoder_optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "            pred_decoder_output = torch.argmax(logits, dim=-1)\n",
    "            # print(pred_decoder_output, \" target: \", train_y[:, 1:])\n",
    "            train_correct += (pred_decoder_output == train_y[:, 1:]).sum().item()\n",
    "\n",
    "\n",
    "        ## validation code\n",
    "        running_loss_val, val_correct = 0, 0\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        for j,(val_x,val_y) in enumerate(val_loader):\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "\n",
    "            encoder_output = encoder(val_x)\n",
    "            logits, loss = decoder(val_y[:, :-1], encoder_output, val_y[:, 1:])\n",
    "\n",
    "            running_loss_val += loss\n",
    "            pred_decoder_output = torch.argmax(logits, dim=-1)\n",
    "            val_correct += torch.sum(pred_decoder_output == val_y[:, 1:])\n",
    "\n",
    "\n",
    "        if running_loss_val < least_error:\n",
    "            least_error = running_loss_val\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "\n",
    "        if no_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {i}\")\n",
    "            break\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train_loss\": running_loss / len(train_data),\n",
    "                \"val_loss\": (running_loss_val/len(val_data)),\n",
    "                \"train_acc\": ((train_correct*100) / (len(train_data)* (decoder_block_size-1))),\n",
    "                \"val_acc\": ((val_correct*100)/(len(val_data)* (decoder_block_size-1))),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxzRR9cjEGDm"
   },
   "source": [
    "## run sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295,
     "referenced_widgets": [
      ""
     ]
    },
    "id": "u_QFbYe32t7r",
    "outputId": "97153eab-b36f-454b-9fed-53ae0287aee1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3o6074mu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06495675751598949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_140036-3o6074mu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/3o6074mu' target=\"_blank\">good-sweep-1</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/3o6074mu' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/3o6074mu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████▊                       | 36/50 [24:27<09:30, 40.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▃▄▄▅▅▄▄▄▄▄▅▆▂▄▇▇▆▅▄▅▃▃▃▅▃▃▃▃▄▄▅▅▇█</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▃▃▄▃▅▄▄▄▂█▅▂▁▃▃▃▃▅▄▄▃▆▅▅▅▄▄▃▃▂▁</td></tr><tr><td>val_acc</td><td>▂▂▃▄▅▄▂▄▃▄▄▄▅▆▃▄█▅▄▂▃▁▁▃▃▅▂▃▃▂▃▃▆▆▆▆</td></tr><tr><td>val_loss</td><td>▇▆▅▅▄▅▆▆▅▅▅▄▄▃█▄▁▄▅▅▅▇▇▅▅▄█▆▆▆▅▆▃▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>75.60189</td></tr><tr><td>train_loss</td><td>0.00719</td></tr><tr><td>val_acc</td><td>79.19354</td></tr><tr><td>val_loss</td><td>0.00601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-sweep-1</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/3o6074mu' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/3o6074mu</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_140036-3o6074mu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f2qrfdvz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06325632562397139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_142520-f2qrfdvz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/f2qrfdvz' target=\"_blank\">jolly-sweep-2</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/f2qrfdvz' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/f2qrfdvz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.083 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▉                                    | 56/100 [54:35<42:53, 58.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▂▃▄▅▆▃▁▂▄▄▆▅▃▂▃▄▄▂▃▂▇▅▂▂▂▆█▇▄▅▅▅▂▃▄▆▆▆▅▁</td></tr><tr><td>train_loss</td><td>▇▅▅▄▄█▆▅▄▃▃▆▇▆▅▄▇▆▆▅▂▆▆▇▃▁▁▂▄▄▅▄▇▅▄▃▃▃▄▇</td></tr><tr><td>val_acc</td><td>▄▃▅▆▄▆▄▂▄▅▅▆▂▂▃▄▄▁▁▄▆▃▄▄▅▇█▇▅█▅▇▆▂▆▅▇▇█▃</td></tr><tr><td>val_loss</td><td>▆▆▅▅▆▆▇▆▅▅▅▇▇▆▆▅▇█▆▅▅▅▅▅▄▁▁▃▅▄▃▇▃▆▅▃▃▃▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>73.65207</td></tr><tr><td>train_loss</td><td>0.00762</td></tr><tr><td>val_acc</td><td>77.01338</td></tr><tr><td>val_loss</td><td>0.00657</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-sweep-2</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/f2qrfdvz' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/f2qrfdvz</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_142520-f2qrfdvz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7t4l11zq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06567673788630166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_152004-7t4l11zq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/7t4l11zq' target=\"_blank\">divine-sweep-3</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/7t4l11zq' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/7t4l11zq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▎                                     | 54/100 [10:11<08:40, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▄▃▂▅▄▄▅▄▃▃▄▄▃▄▅▆▇▇▇▂▃▅▆▇█▇▆▇▆▅▅▄▄▅▅▆▆▆</td></tr><tr><td>train_loss</td><td>█▅▇▆▆▄▄▄▅▅▆▄▅▄▅▄▃▂▁▂▂▆▆▅▃▂▂▁▂▃▃▃▃▅▄▃▂▂▂▃</td></tr><tr><td>val_acc</td><td>▃▄▃▅▄▅▆▃▅▅▂▄▂▄▄▄▄▅▅▆▅▆▁▂▅▆▇█▆▆▄▅▄▅▄▅▄▅▇▆</td></tr><tr><td>val_loss</td><td>▆█▅▅▆▃▅▄▄█▆▅▆▅▅▅▃▃▃▃▇▆▄▃▃▂▁▂▃▂▄▄▅▄▅▃▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>73.68726</td></tr><tr><td>train_loss</td><td>0.00389</td></tr><tr><td>val_acc</td><td>77.90537</td></tr><tr><td>val_loss</td><td>0.00325</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-3</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/7t4l11zq' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/7t4l11zq</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_152004-7t4l11zq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sprn15hj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02257347420160668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_153029-sprn15hj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/sprn15hj' target=\"_blank\">giddy-sweep-4</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/sprn15hj' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/sprn15hj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [21:59<00:00, 26.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>95.55844</td></tr><tr><td>train_loss</td><td>0.00051</td></tr><tr><td>val_acc</td><td>96.42797</td></tr><tr><td>val_loss</td><td>0.00043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-4</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/sprn15hj' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/sprn15hj</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_153029-sprn15hj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dgyvqndu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0286256627835069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_155303-dgyvqndu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/dgyvqndu' target=\"_blank\">olive-sweep-5</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/dgyvqndu' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/dgyvqndu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 40/40 [17:46<00:00, 26.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>train_loss</td><td>█▆▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████▇█▇▇</td></tr><tr><td>val_loss</td><td>█▆▆▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>87.06459</td></tr><tr><td>train_loss</td><td>0.00166</td></tr><tr><td>val_acc</td><td>91.00903</td></tr><tr><td>val_loss</td><td>0.0011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-5</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/dgyvqndu' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/dgyvqndu</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_155303-dgyvqndu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4mw8e64o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.011861753734323697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_161103-4mw8e64o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/4mw8e64o' target=\"_blank\">effortless-sweep-6</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/4mw8e64o' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/4mw8e64o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [22:43<00:00, 27.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇███████▇████████████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>96.10641</td></tr><tr><td>train_loss</td><td>0.00044</td></tr><tr><td>val_acc</td><td>96.68374</td></tr><tr><td>val_loss</td><td>0.0004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-6</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/4mw8e64o' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/4mw8e64o</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_161103-4mw8e64o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cgkm9666 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007296185855534168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_163353-cgkm9666</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/cgkm9666' target=\"_blank\">northern-sweep-7</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/cgkm9666' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/cgkm9666</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 40/40 [18:48<00:00, 28.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇▇█▇████▇▇███████▇████</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>97.40063</td></tr><tr><td>train_loss</td><td>0.00029</td></tr><tr><td>val_acc</td><td>96.85211</td></tr><tr><td>val_loss</td><td>0.0004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-7</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/cgkm9666' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/cgkm9666</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_163353-cgkm9666/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x7lyojxw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.015215530714441816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_165249-x7lyojxw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/x7lyojxw' target=\"_blank\">dauntless-sweep-8</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/x7lyojxw' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/x7lyojxw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 40/40 [16:11<00:00, 24.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▇▇▇▇▇██▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>96.97322</td></tr><tr><td>train_loss</td><td>0.00034</td></tr><tr><td>val_acc</td><td>96.7822</td></tr><tr><td>val_loss</td><td>0.0004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-8</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/x7lyojxw' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/x7lyojxw</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_165249-x7lyojxw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ol3n0jph with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0023829004625305324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_170919-ol3n0jph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ol3n0jph' target=\"_blank\">atomic-sweep-9</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ol3n0jph' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ol3n0jph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 20/20 [07:45<00:00, 23.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▆▇▇▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▇▇▇▇▇██████████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>97.05419</td></tr><tr><td>train_loss</td><td>0.00033</td></tr><tr><td>val_acc</td><td>96.65926</td></tr><tr><td>val_loss</td><td>0.00042</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-sweep-9</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ol3n0jph' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ol3n0jph</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_170919-ol3n0jph/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 86triun7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.030047885208825384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_171713-86triun7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/86triun7' target=\"_blank\">jolly-sweep-10</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/86triun7' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/86triun7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 40/40 [19:19<00:00, 28.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▃▃▃▃▃▃▃▄▄▄▄▅▄▄▅▅▅▅▅▅▆▆▇▇▇▇█████▇▅▄▄▅▅▅▅</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▆▅▆▅▅▅▅▄▅▄▄▄▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▂▃▄▄▄▄▄▄</td></tr><tr><td>val_acc</td><td>▁▂▂▂▂▂▂▂▃▃▃▄▄▃▄▄▄▄▄▅▅▆▆▇▇▇█▇███▇▇▄▄▄▄▄▄▄</td></tr><tr><td>val_loss</td><td>█▇▆▆▆▇▆▆▆▆▅▅▅▅▅▅▅▄▅▄▃▃▂▂▂▂▁▁▁▁▁▂▂▅▅▅▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>83.87774</td></tr><tr><td>train_loss</td><td>0.00216</td></tr><tr><td>val_acc</td><td>86.87244</td></tr><tr><td>val_loss</td><td>0.00176</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-sweep-10</strong> at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/86triun7' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/86triun7</a><br> View project at: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_171713-86triun7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ay9in1mq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006086129056137431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/English-Hindi-Transliteration-using-Deep-Learning/notebooks/wandb/run-20251016_173646-ay9in1mq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ay9in1mq' target=\"_blank\">devoted-sweep-11</a></strong> to <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/sweeps/olbj21xb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ay9in1mq' target=\"_blank\">https://wandb.ai/sshejole132-iit-bombay/Tranliteration-Tranformers/runs/ay9in1mq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████▊                            | 33/50 [14:26<07:13, 25.50s/it]"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id=sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNtTaEc6kxuC"
   },
   "source": [
    "# Test Time\n",
    "Since this is the best model(validation accuracy) , we will train it on both train and validation data.\n",
    "We will then test the model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcgfjfD9lvWJ"
   },
   "source": [
    "## Best Hyperparameter from validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "q7SXqJhekxuC",
    "outputId": "17c0dfd2-2e0b-4449-80fe-9f7a2ce68c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hyperparameters set successfully\n"
     ]
    }
   ],
   "source": [
    "n_embd = 64\n",
    "batch_size = 256\n",
    "learning_rate = 0.003699\n",
    "n_head = 4\n",
    "n_layers = 2\n",
    "dropout = 0\n",
    "epochs = 20\n",
    "\n",
    "encoder = Encoder(n_embd, n_head, n_layers, dropout)\n",
    "decoder = Decoder(n_embd, n_head, n_layers, dropout)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "print(\"✅ Hyperparameters set successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0-9k1L6l0iZ"
   },
   "source": [
    "## Train on train_data + val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TQVFJyvlTMjS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.787 K model parameters\n",
      "Step:  0\n",
      "train_loss:  0.0017554496738523468\n",
      "train_acc:  87.72230771346956\n",
      "Step:  5\n",
      "train_loss:  0.00042737022913588274\n",
      "train_acc:  96.22755506524322\n",
      "Step:  10\n",
      "train_loss:  0.0003673466991669639\n",
      "train_acc:  96.74785026948025\n",
      "Step:  15\n",
      "train_loss:  0.0003365819262775884\n",
      "train_acc:  96.99969251009615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum([p.numel() for p in encoder.parameters()] + [p.numel() for p in decoder.parameters()])/1e3, 'K model parameters')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "encoder_optimizer = torch.optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('Step | Training Loss | Validation Loss   |   Training Accuracy %  |  Validation Accuracy %')\n",
    "\n",
    "least_error = float('inf')\n",
    "patience = 20  # The number of epochs without improvement to wait before stopping\n",
    "no_improvement = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for j,(train_x,train_y) in enumerate(train_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad(set_to_none=True)\n",
    "        decoder_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        encoder_output = encoder(train_x)\n",
    "        logits, loss = decoder(train_y[:, :-1], encoder_output, train_y[:, 1:])\n",
    "\n",
    "        encoder_optimizer.zero_grad(set_to_none=True)\n",
    "        decoder_optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "        pred_decoder_output = torch.argmax(logits, dim=-1)\n",
    "        # print(pred_decoder_output, \" target: \", train_y[:, 1:])\n",
    "        train_correct += (pred_decoder_output == train_y[:, 1:]).sum().item()\n",
    "\n",
    "    for j,(train_x,train_y) in enumerate(val_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "\n",
    "        encoder_optimizer.zero_grad(set_to_none=True)\n",
    "        decoder_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        encoder_output = encoder(train_x)\n",
    "        logits, loss = decoder(train_y[:, :-1], encoder_output, train_y[:, 1:])\n",
    "\n",
    "        encoder_optimizer.zero_grad(set_to_none=True)\n",
    "        decoder_optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "        pred_decoder_output = torch.argmax(logits, dim=-1)\n",
    "        # print(pred_decoder_output, \" target: \", train_y[:, 1:])\n",
    "        train_correct += (pred_decoder_output == train_y[:, 1:]).sum().item()\n",
    "\n",
    "\n",
    "    metrics = {\n",
    "            \"train_loss\": running_loss.cpu().detach().numpy() / (len(train_data)+len(val_data)),\n",
    "            \"train_acc\": ((train_correct*100) / ((len(train_data)+len(val_data))* (decoder_block_size-1))),\n",
    "        }\n",
    "    if i % 5 == 0:\n",
    "        print(\"Step: \",i)\n",
    "        print(\"train_loss: \", metrics[\"train_loss\"])\n",
    "        print(\"train_acc: \", metrics[\"train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hAjg5s0IkxuC"
   },
   "outputs": [],
   "source": [
    "PATH = 'models/transformer-encoder.pth'\n",
    "torch.save(encoder, PATH)\n",
    "PATH = 'models/transformer-decoder.pth'\n",
    "torch.save(decoder, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4M3aMxTl-zb"
   },
   "source": [
    "## generate output sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mfIxu6njkxuD"
   },
   "outputs": [],
   "source": [
    "def generate(input):\n",
    "    B, T = input.shape\n",
    "    encoder_output = encoder(input)\n",
    "    idx = torch.full((B, 1), 2, dtype=torch.long, device=device) # (B,1)\n",
    "\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(decoder_block_size-1):\n",
    "        # get the predictions\n",
    "        logits, loss = decoder(idx, encoder_output) # logits (B, T, vocab_size)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :] # becomes (B, C)\n",
    "        # apply softmax to get probabilities\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True) # (B, 1)\n",
    "        # append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeB2nYeFmXy8"
   },
   "source": [
    "## Check Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dIzXiSLBkxuD",
    "outputId": "ebe1d201-32bb-4372-e64a-62ebe173799d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def check(encoder, decoder, test_data, device='cpu', batch_size=64, pad_idx=0):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - word-level accuracy: fraction of sequences where all non-pad tokens match exactly\n",
    "      - char-level accuracy: fraction of non-pad tokens that are predicted correctly\n",
    "      - avg validation loss (per-batch loss averaged over batches)\n",
    "    Parameters:\n",
    "      encoder, decoder : your models\n",
    "      test_data         : dataset (not a dataloader) or anything accepted by DataLoader\n",
    "      device            : 'cpu' or 'cuda'\n",
    "      batch_size        : dataloader batch size\n",
    "      pad_idx           : integer index used for padding tokens; set to None to not mask pads\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    total_sequences = 0           # total number of sequences (examples)\n",
    "    total_nonpad_tokens = 0       # total number of non-pad tokens counted across all sequences\n",
    "    char_correct = 0              # count of correctly predicted tokens (char-level)\n",
    "    word_exact_correct = 0        # count of sequences with exact match on all non-pad tokens\n",
    "    running_loss_val = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in test_loader:\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "\n",
    "            # generate should produce token predictions of same shape as val_y\n",
    "            output = generate(val_x)  # expected shape: (batch, seq_len)\n",
    "            # get logits and loss from decoder as before; decoder returns (logits, loss)\n",
    "            encoder_output = encoder(val_x)\n",
    "            logits, loss = decoder(val_y[:, :-1], encoder_output, val_y[:, 1:])\n",
    "            # accumulate scalar loss\n",
    "            running_loss_val += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "            # Align lengths: compare output[:,1:] with val_y[:,1:]\n",
    "            pred = output[:, 1:]\n",
    "            target = val_y[:, 1:]\n",
    "\n",
    "            # ensure same shape (if generate produced different length, adjust or slice)\n",
    "            min_len = min(pred.size(1), target.size(1))\n",
    "            pred = pred[:, :min_len]\n",
    "            target = target[:, :min_len]\n",
    "\n",
    "            if pad_idx is not None:\n",
    "                mask = (target != pad_idx)          # True where token is not padding\n",
    "                nonpad_count = mask.sum().item()\n",
    "                # char-level correct: count positions where pred == target and target != pad\n",
    "                char_correct += ( (pred == target) & mask ).sum().item()\n",
    "                total_nonpad_tokens += nonpad_count\n",
    "\n",
    "                # word-level exact: for each sequence, check equality only on non-pad positions\n",
    "                # If a sequence has zero nonpad tokens (weird), treat as not correct.\n",
    "                seq_equal = torch.all( ((pred == target) | (~mask)), dim=1 )\n",
    "                # but we should exclude sequences with zero nonpad tokens from denominator:\n",
    "                nonpad_per_seq = mask.sum(dim=1)\n",
    "                valid_seq_mask = (nonpad_per_seq > 0)\n",
    "                if valid_seq_mask.any():\n",
    "                    word_exact_correct += seq_equal[valid_seq_mask].sum().item()\n",
    "                    total_sequences += valid_seq_mask.sum().item()\n",
    "                # sequences with zero nonpad tokens are ignored for word-level stats\n",
    "            else:\n",
    "                # no padding: count all positions\n",
    "                total_nonpad_tokens += target.numel()\n",
    "                char_correct += (pred == target).sum().item()\n",
    "\n",
    "                seq_equal = torch.all(pred == target, dim=1)\n",
    "                word_exact_correct += seq_equal.sum().item()\n",
    "                total_sequences += pred.size(0)\n",
    "\n",
    "    # final metrics\n",
    "    avg_loss = running_loss_val / n_batches if n_batches > 0 else float('nan')\n",
    "    char_acc = (char_correct / total_nonpad_tokens * 100.0) if total_nonpad_tokens > 0 else float('nan')\n",
    "    word_acc = (word_exact_correct / total_sequences * 100.0) if total_sequences > 0 else float('nan')\n",
    "\n",
    "    print(f\"Validation avg loss (per-batch): {avg_loss:.6f}\")\n",
    "    print(f\"Char-level accuracy (non-pad tokens): {char_acc:.4f}%  ({char_correct}/{total_nonpad_tokens})\")\n",
    "    print(f\"Word-level (sequence-exact) accuracy: {word_acc:.4f}%  ({word_exact_correct}/{total_sequences})\")\n",
    "\n",
    "    return {\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"char_acc\": char_acc,\n",
    "        \"word_acc\": word_acc,\n",
    "        \"char_correct\": char_correct,\n",
    "        \"total_nonpad_tokens\": total_nonpad_tokens,\n",
    "        \"word_exact_correct\": word_exact_correct,\n",
    "        \"total_sequences\": total_sequences\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check2(encoder, decoder, test_data, device='cpu', batch_size=64, pad_idx=0, max_bleu_n=4):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      - word-level accuracy: fraction of sequences where all non-pad tokens match exactly\n",
    "      - char-level accuracy: fraction of non-pad tokens that are predicted correctly\n",
    "      - CER (Character Error Rate)\n",
    "      - BLEU (sentence-level, character-based)\n",
    "      - avg validation loss (per-batch loss averaged over batches)\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    total_sequences = 0\n",
    "    total_nonpad_tokens = 0\n",
    "    char_correct = 0\n",
    "    word_exact_correct = 0\n",
    "    running_loss_val = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    total_edit_distance = 0\n",
    "    total_chars_for_cer = 0\n",
    "    total_bleu = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in test_loader:\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "\n",
    "            # generate predicted sequences\n",
    "            output = generate(val_x)  # shape: (batch, seq_len)\n",
    "\n",
    "            # compute decoder loss as before\n",
    "            encoder_output = encoder(val_x)\n",
    "            logits, loss = decoder(val_y[:, :-1], encoder_output, val_y[:, 1:])\n",
    "            running_loss_val += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "            pred = output[:, 1:]\n",
    "            target = val_y[:, 1:]\n",
    "\n",
    "            # align lengths\n",
    "            min_len = min(pred.size(1), target.size(1))\n",
    "            pred = pred[:, :min_len]\n",
    "            target = target[:, :min_len]\n",
    "\n",
    "            # convert tensors to lists of integers\n",
    "            pred_list = pred.tolist()\n",
    "            target_list = target.tolist()\n",
    "\n",
    "            for p_seq, t_seq in zip(pred_list, target_list):\n",
    "                # mask padding if needed\n",
    "                if pad_idx is not None:\n",
    "                    mask = [t != pad_idx for t in t_seq]\n",
    "                    p_seq_masked = [p for p, m in zip(p_seq, mask) if m]\n",
    "                    t_seq_masked = [t for t, m in zip(t_seq, mask) if m]\n",
    "                else:\n",
    "                    p_seq_masked = p_seq\n",
    "                    t_seq_masked = t_seq\n",
    "\n",
    "                if len(t_seq_masked) == 0:\n",
    "                    continue\n",
    "\n",
    "                # char-level correct\n",
    "                char_correct += sum(p == t for p, t in zip(p_seq_masked, t_seq_masked))\n",
    "                total_nonpad_tokens += len(t_seq_masked)\n",
    "\n",
    "                # word-level exact\n",
    "                if p_seq_masked == t_seq_masked:\n",
    "                    word_exact_correct += 1\n",
    "                total_sequences += 1\n",
    "\n",
    "                # CER\n",
    "                total_edit_distance += levenshtein_distance(p_seq_masked, t_seq_masked)\n",
    "                total_chars_for_cer += len(t_seq_masked)\n",
    "\n",
    "                # BLEU\n",
    "                total_bleu += sentence_bleu(t_seq_masked, p_seq_masked, max_n=max_bleu_n)\n",
    "\n",
    "    avg_loss = running_loss_val / n_batches if n_batches > 0 else float('nan')\n",
    "    char_acc = char_correct / total_nonpad_tokens * 100.0 if total_nonpad_tokens > 0 else float('nan')\n",
    "    word_acc = word_exact_correct / total_sequences * 100.0 if total_sequences > 0 else float('nan')\n",
    "    cer = total_edit_distance / total_chars_for_cer if total_chars_for_cer > 0 else float('nan')\n",
    "    avg_bleu = total_bleu / total_sequences if total_sequences > 0 else float('nan')\n",
    "\n",
    "    print(f\"Validation avg loss (per-batch): {avg_loss:.6f}\")\n",
    "    print(f\"Char-level accuracy (non-pad tokens): {char_acc:.4f}%  ({char_correct}/{total_nonpad_tokens})\")\n",
    "    print(f\"Word-level (sequence-exact) accuracy: {word_acc:.4f}%  ({word_exact_correct}/{total_sequences})\")\n",
    "    print(f\"Character Error Rate (CER): {cer:.4f}\")\n",
    "    print(f\"Average BLEU (char-based): {avg_bleu:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"char_acc\": char_acc,\n",
    "        \"word_acc\": word_acc,\n",
    "        \"cer\": cer,\n",
    "        \"bleu\": avg_bleu,\n",
    "        \"char_correct\": char_correct,\n",
    "        \"total_nonpad_tokens\": total_nonpad_tokens,\n",
    "        \"word_exact_correct\": word_exact_correct,\n",
    "        \"total_sequences\": total_sequences\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Make sure Encoder and Decoder class definitions are already imported or defined above this line!\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load saved encoder and decoder\n",
    "encoder = torch.load('models/transformer-encoder.pth', map_location=device)\n",
    "decoder = torch.load('models/transformer-decoder.pth', map_location=device)\n",
    "\n",
    "# Put them in eval mode before testing\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "print(\"Models loaded successfully on\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_lang and output_lang saved successfully in 'models/' directory.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save input_lang\n",
    "with open(os.path.join(\"models\", \"input_lang.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(input_lang, f)\n",
    "\n",
    "# Save output_lang\n",
    "with open(os.path.join(\"models\", \"output_lang.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(output_lang, f)\n",
    "\n",
    "print(\"input_lang and output_lang saved successfully in 'models/' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "28\n",
      "30\n",
      "28\n",
      "30\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0][0]))\n",
    "print(len(train_data[0][1]))\n",
    "print(len(val_data[0][0]))\n",
    "print(len(val_data[0][1]))\n",
    "print(len(test_data[0][0]))\n",
    "print(len(test_data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "print(input_vocab_size)\n",
    "print(output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation avg loss (per-batch): 0.112573\n",
      "Char-level accuracy (non-pad tokens): 71.6944%  (49819/69488)\n",
      "Word-level (sequence-exact) accuracy: 42.0392%  (4251/10112)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_loss': 0.1125725770156972,\n",
       " 'char_acc': 71.69439327653696,\n",
       " 'word_acc': 42.03916139240506,\n",
       " 'char_correct': 49819,\n",
       " 'total_nonpad_tokens': 69488,\n",
       " 'word_exact_correct': 4251,\n",
       " 'total_sequences': 10112}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder specific detail\n",
    "input_vocab_size = input_lang.vocab_size\n",
    "encoder_block_size = len(train_data[0][0])\n",
    "\n",
    "# decoder specific detail\n",
    "output_vocab_size = output_lang.vocab_size\n",
    "decoder_block_size = len(train_data[0][1])\n",
    "\n",
    "check(encoder, decoder, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation avg loss (per-batch): 0.112573\n",
      "Char-level accuracy (non-pad tokens): 71.6944%  (49819/69488)\n",
      "Word-level (sequence-exact) accuracy: 42.0392%  (4251/10112)\n",
      "Character Error Rate (CER): 0.2009\n",
      "Average BLEU (char-based): 73.0857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_loss': 0.1125725770156972,\n",
       " 'char_acc': 71.69439327653696,\n",
       " 'word_acc': 42.03916139240506,\n",
       " 'cer': 0.20089799677642184,\n",
       " 'bleu': 73.08571634442133,\n",
       " 'char_correct': 49819,\n",
       " 'total_nonpad_tokens': 69488,\n",
       " 'word_exact_correct': 4251,\n",
       " 'total_sequences': 10112}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check2(encoder, decoder, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def transliterate_word(word, input_lang, output_lang,\n",
    "                       encoder, decoder, device='cpu',\n",
    "                       input_max_len=30, output_max_len=30):\n",
    "    \"\"\"\n",
    "    Transliterates a single English word using your trained encoder-decoder setup.\n",
    "\n",
    "    Args:\n",
    "        word (str): English word to transliterate\n",
    "        input_lang, output_lang: objects with char2index (and optionally index2char)\n",
    "        encoder, decoder: trained models\n",
    "        device (str): 'cpu' or 'cuda'\n",
    "        input_max_len, output_max_len: max sequence lengths (used for padding)\n",
    "\n",
    "    Returns:\n",
    "        predicted_text (str): transliterated output\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # build inverse map for output indices\n",
    "    if hasattr(output_lang, 'index2char'):\n",
    "        idx2char = output_lang.index2char\n",
    "    else:\n",
    "        idx2char = {v: k for k, v in output_lang.char2index.items()}\n",
    "\n",
    "    # unknown and padding chars\n",
    "    unknown = input_lang.char2index.get('$', 0)\n",
    "    pad_char = '#'\n",
    "\n",
    "    # pad the word to match training preprocessing\n",
    "    inp = word.ljust(input_max_len + 1, pad_char)\n",
    "    input_tensor = torch.zeros((1, input_max_len + 1), dtype=torch.long, device=device)\n",
    "    for i, ch in enumerate(inp):\n",
    "        input_tensor[0, i] = input_lang.char2index.get(ch, unknown)\n",
    "\n",
    "    # generate prediction\n",
    "    with torch.no_grad():\n",
    "        output_idx = generate(input_tensor)  # (1, seq_len)\n",
    "        output_idx = output_idx[0].cpu().tolist()\n",
    "\n",
    "    # convert to text: skip start (^), pad (#), unknown ($)\n",
    "    predicted_chars = []\n",
    "    for i in output_idx:\n",
    "        ch = idx2char.get(i, '')\n",
    "        if ch in ['#', '^', '$']:\n",
    "            continue\n",
    "        predicted_chars.append(ch)\n",
    "\n",
    "    predicted_text = ''.join(predicted_chars).strip()\n",
    "\n",
    "    print(f\"Input : {word}\")\n",
    "    print(f\"Output: {predicted_text}\")\n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/opt/pytorch/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [15,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransliterate_word\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 41\u001b[0m, in \u001b[0;36mtransliterate_word\u001b[0;34m(word, input_lang, output_lang, encoder, decoder, device, input_max_len, output_max_len)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# generate prediction\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     output_idx \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1, seq_len)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     output_idx \u001b[38;5;241m=\u001b[39m output_idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# convert to text: skip start (^), pad (#), unknown ($)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m      2\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 3\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((B, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;66;03m# (B,1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# idx is (B, T) array of indices in the current context\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 103\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,n_embd)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,n_embd)\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# apply one attention layer (B,T,C)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 84\u001b[0m, in \u001b[0;36mencoderBlock.forward\u001b[0;34m(self, x, encoder_output)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, encoder_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 84\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, encoder_output)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, encoder_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x, encoder_output) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, encoder_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mHead.forward\u001b[0;34m(self, x, encoder_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x) \u001b[38;5;66;03m# (B,T,d_k)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,d_k)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# compute attention scores\u001b[39;00m\n\u001b[1;32m     25\u001b[0m wei \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m C\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;66;03m# (B,T,T)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "transliterate_word(\"ram\", input_lang, output_lang, encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def build_index2char(lang):\n",
    "    \"\"\"Return index->char dict for a language object that has char2index.\n",
    "       If lang already has index2char attribute, use it.\"\"\"\n",
    "    if hasattr(lang, 'index2char'):\n",
    "        return lang.index2char\n",
    "    inv = {idx: ch for ch, idx in lang.char2index.items()}\n",
    "    return inv\n",
    "\n",
    "def test_word(word,\n",
    "              input_lang, output_lang,\n",
    "              encoder, decoder, generate,\n",
    "              input_max_len, output_max_len,\n",
    "              device='cpu'):\n",
    "    \"\"\"\n",
    "    Test a single English word using your preprocess function.\n",
    "    - word: string (e.g., 'kumar')\n",
    "    - input_lang, output_lang: objects with char2index (and optionally index2char)\n",
    "    - encoder, decoder, generate: trained model pieces (generate takes batched inputs)\n",
    "    - input_max_len, output_max_len: ints used in preprocess\n",
    "    - device: 'cpu' or 'cuda'\n",
    "    Returns predicted string (transliteration).\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # prepare a dummy output (preprocess needs data[1])\n",
    "    data = ( [word], [''] )  # input list, output list (empty target used only for shaping)\n",
    "\n",
    "    # create dataset (uses device internally when creating tensors)\n",
    "    ds = preprocess(data, input_lang, output_lang, input_max_len, output_max_len, s=f\"single '{word}'\")\n",
    "\n",
    "    # DataLoader for a single example\n",
    "    loader = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    # build index->char mapping for the output language\n",
    "    idx2char = build_index2char(output_lang)\n",
    "\n",
    "    # run inference\n",
    "    with torch.no_grad():\n",
    "        for inp_batch, _ in loader:\n",
    "            inp_batch = inp_batch.to(device).long()   # shape: (1, input_len+1)\n",
    "            # If your encoder expects shape (batch, seq_len) this is fine.\n",
    "            # Use generate() to produce predicted token ids (batch, out_seq_len)\n",
    "            pred_ids = generate(inp_batch)            # assume tensor of token ids\n",
    "\n",
    "            # if generate returns logits, convert to ids\n",
    "            if pred_ids.dim() == 3:  # (batch, seq_len, vocab)\n",
    "                pred_ids = pred_ids.argmax(-1)\n",
    "\n",
    "            pred_ids = pred_ids[0].cpu().tolist()  # list of token ids for this single example\n",
    "\n",
    "            # Map ids to chars, filter out start '^' and padding '#'\n",
    "            # In your preprocessing: '^' is start, '#' is padding, '$' is unknown\n",
    "            # Keep characters until end (we will ignore '#' and '^' if present)\n",
    "            chars = []\n",
    "            for tid in pred_ids:\n",
    "                ch = idx2char.get(tid, None)\n",
    "                if ch is None:\n",
    "                    # unknown index: skip or replace with '?'\n",
    "                    continue\n",
    "                if ch == '^':    # skip start symbol if it appears\n",
    "                    continue\n",
    "                if ch == '#':    # skip padding\n",
    "                    continue\n",
    "                # optional: stop at EOS if you have one (e.g., ch == '$' used differently)\n",
    "                # append otherwise\n",
    "                chars.append(ch)\n",
    "\n",
    "            predicted = ''.join(chars).strip()\n",
    "\n",
    "            print(f\"Input : {word}\")\n",
    "            print(f\"Output: {predicted}\")\n",
    "\n",
    "            return predicted\n",
    "\n",
    "    # if loader was empty for some reason\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_word\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_max_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_max_len\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 33\u001b[0m, in \u001b[0;36mtest_word\u001b[0;34m(word, input_lang, output_lang, encoder, decoder, generate, input_max_len, output_max_len, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m data \u001b[38;5;241m=\u001b[39m ( [word], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m] )  \u001b[38;5;66;03m# input list, output list (empty target used only for shaping)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# create dataset (uses device internally when creating tensors)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_max_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_max_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mword\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# DataLoader for a single example\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(data, input_lang, output_lang, input_max_len, output_max_len, s)\u001b[0m\n\u001b[1;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((n, output_max_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m), device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 12\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mljust(input_max_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m data[\u001b[38;5;241m1\u001b[39m][i]       \u001b[38;5;66;03m# add start symbol to output\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     op \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mljust(output_max_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_word(\"word\", input_lang, output_lang, encoder, decoder, generate, input_max_len, output_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDP4KvWdFnIL"
   },
   "source": [
    "# Plotting the Attention HeatMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WfJEdcgFmiI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.font_manager import FontProperties\n",
    "tel_font = FontProperties(fname = 'TiroDevanagariHindi-Regular.ttf')\n",
    "# Assuming you have attention_weights of shape (batch_size, output_sequence_length, batch_size, input_sequence_length)\n",
    "# and prediction_matrix of shape (batch_size, output_sequence_length)\n",
    "# and input_matrix of shape (batch_size, input_sequence_length)\n",
    "\n",
    "# Define the grid dimensions\n",
    "rows = int(np.ceil(np.sqrt(12)))\n",
    "cols = int(np.ceil(12 / rows))\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(9, 9))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < 12:\n",
    "        prediction = [opLang.index2char[j.item()] for j in pred[i+1]]\n",
    "\n",
    "        pred_word=\"\"\n",
    "        input_word=\"\"\n",
    "\n",
    "        for j in range(len(prediction)):\n",
    "            # Ignore padding\n",
    "            if(prediction[j] != '#'):\n",
    "                pred_word += prediction[j]\n",
    "            else :\n",
    "                break\n",
    "        input_seq = [ipLang.index2char[j.item()] for j in testData[i][0]]\n",
    "\n",
    "        for j in range(len(input_seq)):\n",
    "            if(input_seq[j] != '#'):\n",
    "                    input_word += input_seq[j]\n",
    "            else :\n",
    "                break\n",
    "        attn_weights = atten_weights[i, :len(pred_word), :len(input_word)].detach().cpu().numpy()\n",
    "        ax.imshow(attn_weights.T, cmap='hot', interpolation='nearest')\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.set_title(f'Example {i+1}')\n",
    "        ax.set_xlabel('Output predicted')\n",
    "        ax.set_ylabel('Input word')\n",
    "        ax.set_xticks(np.arange(len(pred_word)))\n",
    "        ax.set_xticklabels(pred_word, rotation = 90, fontproperties = tel_font,fontdict={'fontsize':8})\n",
    "        ax.xaxis.tick_top()\n",
    "\n",
    "        ax.set_yticks(np.arange(len(input_word)))\n",
    "        ax.set_yticklabels(input_word, rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "wandb.init(project='CS6910_Assignment_3')\n",
    "\n",
    "# Convert the matplotlib figure to an image\n",
    "fig.canvas.draw()\n",
    "image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "# Log the image in wandb\n",
    "wandb.log({\"attention_heatmaps\": [wandb.Image(image)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnHR_oql6-S4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hRdpoWePeYHn",
    "44xIRolL_T_d",
    "XdltQ7oJCq1j",
    "GgPU486JC8Mz",
    "658W9RARGEUf",
    "q7fAgs5uQni_",
    "n4rGh7vuQqaa",
    "nvyRJWUUbR2f",
    "8ETW0BG_Pa24",
    "MQPGy32rnD3V",
    "z_aYZvDD1OHU",
    "pKvBd5mKf0Hf",
    "FYMa5jTQRUaB",
    "zfuv5FoA1wt2",
    "W7CYNChRGuGK"
   ],
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4721249,
     "sourceId": 8013732,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
