{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DDghhjha-xUK"
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ADfNyi1sB9L3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1760765164.080516] [bfd74565809f:5385 :f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 18 05:26:06 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.5     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   48C    P0              80W / 300W |   8925MiB / 81920MiB |     73%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          Off | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              46W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          Off | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   58C    P0              80W / 300W |   2830MiB / 81920MiB |     19%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          Off | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              59W / 300W |    663MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "299AqvvaEdkf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# path = '/kaggle/input/marathi/mar_train.csv'\n",
    "# path_val = '/kaggle/input/marathi/mar_valid.csv'\n",
    "# path_test = '/kaggle/input/marathi/mar_test.csv'\n",
    "\n",
    "lang = 'hin'\n",
    "path = f\"../../aks_dataset/{lang}/train.csv\"\n",
    "path_val = f\"../../aks_dataset/{lang}/valid.csv\"\n",
    "path_test = f\"../../aks_dataset/{lang}/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtpQ9UGxFhkU",
    "outputId": "f1e70afc-85a2-4816-94cd-00e207f0d9ac"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path , header = None)\n",
    "df_val = pd.read_csv(path_val , header = None)\n",
    "df_test = pd.read_csv(path_test , header = None)\n",
    "english_words_val = df_val[0]\n",
    "marathi_words_val = df_val[1]\n",
    "english_words_test = df_test[0]\n",
    "marathi_words_test = df_test[1]\n",
    "english_words = df[0]\n",
    "marathi_words = df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtlfObKubBNq",
    "outputId": "6f0701f1-4823-47fc-b128-56c9446fd71a"
   },
   "outputs": [],
   "source": [
    "# creating list of charecters in both languages\n",
    "\n",
    "english_char_list = []\n",
    "max_length_word_english = -1\n",
    "for word in english_words:\n",
    "  max_length_word_english = max(max_length_word_english,len(word)) \n",
    "  for char in word :\n",
    "    english_char_list.append(char);\n",
    "english_char_list = list(set(english_char_list))\n",
    "english_char_list.sort()\n",
    "\n",
    "marathi_char_list = []\n",
    "max_length_word_marathi = -1\n",
    "for word in marathi_words:\n",
    "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
    "  for char in word :\n",
    "    marathi_char_list.append(char);\n",
    "marathi_char_list = list(set(marathi_char_list))\n",
    "marathi_char_list.sort()\n",
    "\n",
    "\n",
    "# finding out the maximum size word for english and marathi from validation and test data.\n",
    "for word in english_words_val:\n",
    "  max_length_word_english = max(max_length_word_english,len(word))\n",
    "for word in english_words_test:\n",
    "  max_length_word_english = max(max_length_word_english,len(word)) \n",
    "for word in marathi_words_val:\n",
    "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n",
    "for word in marathi_words_test:\n",
    "  max_length_word_marathi = max(max_length_word_marathi,len(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fdcqBaU70W3v"
   },
   "outputs": [],
   "source": [
    "# english word to vector size = 27 ie. max_length_word_english\n",
    "# marathi word to vector size = 20 ie. max_length_word_marathi\n",
    "# for one word.\n",
    "def word2vec(word, lang):\n",
    "  vec = []\n",
    "  if(lang == \"english\"):\n",
    "    vec.append(len(english_char_list) + 1)\n",
    "    for char in word:\n",
    "      for i in range(len(english_char_list)):\n",
    "        if(english_char_list[i] == char):\n",
    "          vec.append(i+1)\n",
    "    while(len(vec) < max_length_word_english + 1): # padding with max_length + 1.\n",
    "        vec.append(0)\n",
    "    vec.append(0)\n",
    "  else :\n",
    "    vec.append(len(marathi_char_list) + 1)\n",
    "    for char in word:\n",
    "      for i in range(len(marathi_char_list)):\n",
    "        if( marathi_char_list[i] == char):\n",
    "          vec.append(i+1)\n",
    "    while(len(vec) < max_length_word_marathi + 1):  # padding with max_length + 1.\n",
    "        vec.append(0)\n",
    "    vec.append(0)\n",
    "  return(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heu_03Y3332P",
    "outputId": "bd542307-bcad-4812-9711-0bf468c89a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ज़ोला\n",
      "[65, 23, 50, 62, 43, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "vec = word2vec(marathi_words[10],\"marathi\")\n",
    "print(marathi_words[10])\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pRObgwk5pcEz"
   },
   "outputs": [],
   "source": [
    "# creating matrix of representation for whole words of english and marathi.\n",
    "\n",
    "def ip_matrix_construct(words, lang):\n",
    "  ans = []\n",
    "  for word in words:\n",
    "    ans.append(word2vec(word, lang))\n",
    "  return(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FgS76C6rluA",
    "outputId": "ef164c52-28ad-470c-f430-b4ab0b25c91f"
   },
   "outputs": [],
   "source": [
    "# calculated representations of whole english and marathi words in variables english and marathi matrix.\n",
    "english_matrix = ip_matrix_construct(english_words, \"english\")\n",
    "marathi_matrix = ip_matrix_construct(marathi_words, \"marathi\")\n",
    "english_matrix = torch.tensor(english_matrix)\n",
    "marathi_matrix = torch.tensor(marathi_matrix)\n",
    "\n",
    "english_matrix_val = ip_matrix_construct(english_words_val, \"english\")\n",
    "marathi_matrix_val = ip_matrix_construct(marathi_words_val, \"marathi\")\n",
    "english_matrix_val = torch.tensor(english_matrix_val)\n",
    "marathi_matrix_val = torch.tensor(marathi_matrix_val)\n",
    "english_matrix_test = ip_matrix_construct(english_words_test, \"english\")\n",
    "marathi_matrix_test =ip_matrix_construct(marathi_words_test, \"marathi\")\n",
    "english_matrix_test = torch.tensor(english_matrix_test)\n",
    "marathi_matrix_test = torch.tensor(marathi_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cvjQGsLrsBJZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self,input_size, embedding_size, hidden_size, enc_layers, p, cell_type, bidirectional):\n",
    "    super(Encoder,self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.enc_layers = enc_layers\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.cell_type = cell_type\n",
    "    self.bidirectional = bidirectional\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "    if(cell_type == \"GRU\"):\n",
    "      self.gru = nn.GRU(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
    "    if(cell_type == \"RNN\"):\n",
    "      self.rnn = nn.RNN(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
    "    if(cell_type == \"LSTM\"):\n",
    "      self.lstm = nn.LSTM(embedding_size, hidden_size, enc_layers, dropout = p, bidirectional = bidirectional)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    if(self.cell_type == \"GRU\"):\n",
    "      output, hidden = self.gru(embedding)\n",
    "    if(self.cell_type == \"RNN\"):\n",
    "      output, hidden = self.rnn(embedding)\n",
    "    if(self.cell_type == \"LSTM\"):\n",
    "      outputs, (hidden,cell) = self.lstm(embedding)\n",
    "      return outputs, hidden, cell\n",
    "    return output, hidden\n",
    "\n",
    "  def initHidden(self):\n",
    "    return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nea9Nz5E-xUP"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.dec_layers = dec_layers\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.cell_type = cell_type\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "    if(cell_type == \"GRU\"):\n",
    "      self.gru = nn.GRU(embedding_size, hidden_size, dec_layers, dropout = p)\n",
    "    if(cell_type == \"RNN\"):\n",
    "      self.rnn = nn.RNN(embedding_size, hidden_size, dec_layers, dropout = p)\n",
    "    if(cell_type == \"LSTM\"):\n",
    "      self.lstm = nn.LSTM(embedding_size, hidden_size, dec_layers, dropout = p)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n",
    "  \n",
    "  def forward(self,x,output, hidden, cell = 0):\n",
    "    x = x.unsqueeze(0).int()\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    if(self.cell_type == \"GRU\"):\n",
    "        outputs, hidden = self.gru(embedding, hidden)\n",
    "    if(self.cell_type == \"RNN\"):\n",
    "        outputs, hidden = self.rnn(embedding, hidden)\n",
    "    if(self.cell_type == \"LSTM\"):\n",
    "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
    "    # shape of outputs: (1, N, hidden_size)\n",
    "    predictions = self.fc(outputs)\n",
    "    # shape of predictions: (1, N, length_of_vocab)\n",
    "    predictions = predictions.squeeze(0)\n",
    "    # shape of predictions: (N, length_of_vocab)\n",
    "    if(self.cell_type == \"LSTM\"):\n",
    "        return predictions, hidden, cell\n",
    "    return predictions, hidden\n",
    "\n",
    "\n",
    "  def initHidden(self):\n",
    "    return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pmqgOzhw0t37"
   },
   "outputs": [],
   "source": [
    "class Atten_decoder(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, bidirectional):\n",
    "    super(Atten_decoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.max_length = len(english_matrix[0])  \n",
    "    self.dec_layers = dec_layers\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.cell_type = cell_type\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "    if(cell_type == \"GRU\"):\n",
    "      self.gru = nn.GRU(hidden_size, hidden_size, dec_layers, dropout = p)\n",
    "    if(cell_type == \"RNN\"):\n",
    "      self.rnn = nn.RNN(hidden_size, hidden_size, dec_layers, dropout = p)\n",
    "    if(cell_type == \"LSTM\"):\n",
    "      self.lstm = nn.LSTM(hidden_size, hidden_size, dec_layers, dropout = p)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)  # fully connected.\n",
    "    self.attn = nn.Linear(hidden_size+embedding_size, self.max_length)\n",
    "    if(bidirectional):\n",
    "      self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size)\n",
    "    else :\n",
    "      self.attn_combine = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "\n",
    "  def forward(self, x,output, hidden, cell = 0):\n",
    "    x = x.unsqueeze(0)\n",
    "    output=output.permute(1,0,2)\n",
    "    embedded = self.embedding(x)\n",
    "    embedded = self.dropout(embedded)\n",
    "    attn_weights = F.softmax(self.attn(torch.cat((embedded[0],hidden[0]), 1)), dim = 1)\n",
    "    attn_applied = torch.bmm(attn_weights.unsqueeze(1),output)\n",
    "    attn_applied = attn_applied.squeeze(1)\n",
    "    op = torch.cat((embedded[0], attn_applied), 1)\n",
    "\n",
    "    op = self.attn_combine(op).unsqueeze(0)\n",
    "    op = F.relu(op)\n",
    "    if(self.cell_type == \"GRU\"):\n",
    "        outputs, hidden = self.gru(op, hidden)\n",
    "    if(self.cell_type == \"RNN\"):\n",
    "        outputs, hidden = self.rnn(op, hidden)\n",
    "    if(self.cell_type == \"LSTM\"):\n",
    "        outputs, (hidden, cell) = self.lstm(op, (hidden, cell))\n",
    "    predictions = self.fc(outputs)\n",
    "    predictions = predictions.squeeze(0)\n",
    "    if(self.cell_type == \"LSTM\"):\n",
    "        return predictions, hidden, cell\n",
    "    return predictions, hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZkWSEAca-Okj"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, cell_type, bidirectional, enc_layers, dec_layers):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(marathi_char_list) + 2  \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        if(self.cell_type == \"LSTM\"):\n",
    "            encoder_output, hidden, cell = self.encoder(source)\n",
    "        else:\n",
    "            encoder_output, hidden = self.encoder(source)\n",
    "        if(self.enc_layers != self.dec_layers or self.bidirectional == True):\n",
    "          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n",
    "          hidden = hidden.repeat(self.dec_layers,1,1)\n",
    "          if(self.cell_type == \"LSTM\"):\n",
    "              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n",
    "              cell = cell.repeat(self.dec_layers,1,1)\n",
    "        \n",
    "        x = target[0]\n",
    "    \n",
    "        for t in range(1, target_len):\n",
    "            if(self.cell_type == \"LSTM\"):\n",
    "                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell)\n",
    "            else :\n",
    "                output, hidden = self.decoder(x, encoder_output, hidden)\n",
    "            outputs[t] = output\n",
    "\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "            \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SYajaq47-xUQ"
   },
   "outputs": [],
   "source": [
    "def Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size):\n",
    "    correct_count = 0\n",
    "    for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
    "        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "        output = model.forward(inp_data.T, target.T, 0)\n",
    "        output = nn.Softmax(dim=2)(output)\n",
    "        output = torch.argmax(output, dim=2)\n",
    "        output = output.T\n",
    "        for i in range(batch_size):\n",
    "            if(torch.equal(output[i][1:],target[i][1:])):\n",
    "                correct_count += 1\n",
    "    accuracy = correct_count * 100 / len(english_matrix)\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Vg6VQCWWzhoy"
   },
   "outputs": [],
   "source": [
    "# creating list of expected marathi word and predicted marathi word.\n",
    "predictions_vanilla_train = []\n",
    "predictions_vanilla_val = []\n",
    "predictions_vanilla_test = []\n",
    "def matrix_to_words(model, english_matrix, marathi_matrix, batch_size, data_type):\n",
    "  for batch_idx in range((int)(len(english_matrix) / batch_size)+1):\n",
    "        inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "        target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "        output = model.forward(inp_data.T, target.T, 0)\n",
    "        output = nn.Softmax(dim=2)(output)\n",
    "        output = torch.argmax(output, dim=2)\n",
    "        output = output.T\n",
    "        for i in range(len(target)):\n",
    "          target_word = target[i]\n",
    "          output_word = output[i]\n",
    "          word1 = \"\"\n",
    "          word2 = \"\"\n",
    "          for j in range(len(target_word)):\n",
    "            if(target_word[j]>0 and target_word[j]<64):\n",
    "              word1 += marathi_char_list[target_word[j] - 1]\n",
    "          for j in range(len(output_word)):\n",
    "            if(output_word[j]>0 and output_word[j]<64):\n",
    "              word2 += marathi_char_list[output_word[j] - 1]\n",
    "          temp = [word1, word2]\n",
    "          if(data_type == \"train\"):\n",
    "            predictions_vanilla_train.append(temp)\n",
    "          if(data_type == \"validation\"):\n",
    "            predictions_vanilla_val.append(temp)\n",
    "          if(data_type == \"test\"):\n",
    "            predictions_vanilla_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9QCnSmaTMRSR"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention):\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 20\n",
    "    input_size_encoder = len(english_char_list) + 2  \n",
    "    input_size_decoder = len(marathi_char_list) + 2  \n",
    "    output_size        = len(marathi_char_list) + 2  \n",
    "\n",
    "    encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, enc_layers, enc_dropout, cell_type,bidirectional).to(device)\n",
    "    if(attention):\n",
    "        decoder_net = Atten_decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type, bidirectional).to(device)\n",
    "    else:\n",
    "        decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,dec_layers,dec_dropout, cell_type).to(device)\n",
    "\n",
    "    model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, enc_layers, dec_layers).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    pad_idx = len(marathi_char_list) + 1  # 64 # pading index for marathi\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print(\"epoch = \",epoch)\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        step = 0\n",
    "        for batch_idx in range((int)(len(english_matrix) / batch_size)):\n",
    "            inp_data = english_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "            target = marathi_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
    "            target = target.T\n",
    "            output = model(inp_data.T, target)\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            step += 1\n",
    "        print(\"total loss = \",total_loss / step)\n",
    "        training_accuracy = Accuracy(model, english_matrix, marathi_matrix, epoch, batch_size)\n",
    "        print(\"Training Accuracy = \", training_accuracy)\n",
    "        val_accuracy = Accuracy(model, english_matrix_val, marathi_matrix_val, epoch, batch_size)\n",
    "        print(\"Validation accuracy = \",val_accuracy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkkdB4_mxLWV",
    "outputId": "b72ad08d-3643-4cb1-c283-cb55a2ad4700"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "total loss =  tensor(0.5212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  20.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                               | 1/20 [01:00<19:03, 60.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  24.335378323108383\n",
      "epoch =  1\n",
      "total loss =  tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  30.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 2/20 [01:40<14:37, 48.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  32.01195532483876\n",
      "epoch =  2\n",
      "total loss =  tensor(0.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  39.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                       | 3/20 [02:21<12:48, 45.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  36.93566147553878\n",
      "epoch =  3\n",
      "total loss =  tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  44.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 4/20 [03:03<11:40, 43.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.41434638980651\n",
      "epoch =  4\n",
      "total loss =  tensor(0.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  48.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 5/20 [03:44<10:40, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.80761365423942\n",
      "epoch =  5\n",
      "total loss =  tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  53.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 6/20 [04:27<10:00, 42.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.79864716061035\n",
      "epoch =  6\n",
      "total loss =  tensor(0.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  56.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▍                                                      | 7/20 [05:12<09:26, 43.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  40.45933616485764\n",
      "epoch =  7\n",
      "total loss =  tensor(0.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  59.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 8/20 [05:57<08:46, 43.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.89303130407425\n",
      "epoch =  8\n",
      "total loss =  tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  61.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▊                                              | 9/20 [06:41<08:02, 43.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.43684127733207\n",
      "epoch =  9\n",
      "total loss =  tensor(0.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  63.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 10/20 [07:25<07:19, 43.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.043574012899164\n",
      "epoch =  10\n",
      "total loss =  tensor(0.0776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  67.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▋                                     | 11/20 [08:09<06:37, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  40.09753028157936\n",
      "epoch =  11\n",
      "total loss =  tensor(0.0676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  68.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 12/20 [08:54<05:55, 44.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  40.36495202139374\n",
      "epoch =  12\n",
      "total loss =  tensor(0.0633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  71.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▉                             | 13/20 [09:38<05:10, 44.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.996381941167215\n",
      "epoch =  13\n",
      "total loss =  tensor(0.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  73.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 14/20 [10:22<04:24, 44.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.52446122384773\n",
      "epoch =  14\n",
      "total loss =  tensor(0.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  77.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████▎                    | 15/20 [11:06<03:40, 44.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.97168475696083\n",
      "epoch =  15\n",
      "total loss =  tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  78.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 16/20 [11:50<02:56, 44.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.54695611137329\n",
      "epoch =  16\n",
      "total loss =  tensor(0.0394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  80.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████▌            | 17/20 [12:34<02:12, 44.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  39.02784332232185\n",
      "epoch =  17\n",
      "total loss =  tensor(0.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  80.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 18/20 [13:19<01:28, 44.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.194116721724086\n",
      "epoch =  18\n",
      "total loss =  tensor(0.0350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  80.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████▊    | 19/20 [14:04<00:44, 44.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  38.93345917885795\n",
      "epoch =  19\n",
      "total loss =  tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training Accuracy =  80.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 20/20 [14:49<00:00, 44.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy =  37.879502910177756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cell_type = \"LSTM\"\n",
    "bidirectional = True\n",
    "enc_layers = 2\n",
    "dec_layers = 2\n",
    "batch_size = 256\n",
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "enc_dropout = 0\n",
    "dec_dropout = 0\n",
    "attention = False\n",
    "\n",
    "\n",
    "model = neural_network(cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_size, hidden_size, enc_dropout, dec_dropout, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_type = \"LSTM\"\n",
    "# bidirectional = False\n",
    "# enc_layers = 2\n",
    "# dec_layers = 2\n",
    "# batch_size = 256\n",
    "# embedding_size = 256\n",
    "# hidden_size = 512\n",
    "# enc_dropout = 0\n",
    "# dec_dropout = 0\n",
    "# attention = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bW22hUA2vTpV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_LSTM_uni_attn.pt\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"models/model_{cell_type}_{'bi' if bidirectional else 'uni'}_{'attn' if attention else 'noattn'}.pt\"\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bW22hUA2vTpV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "torch.save(model, model_name)\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (embedding): Embedding(28, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2)\n",
       "  )\n",
       "  (decoder): Atten_decoder(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (embedding): Embedding(66, 256)\n",
       "    (lstm): LSTM(512, 512, num_layers=2)\n",
       "    (fc): Linear(in_features=512, out_features=66, bias=True)\n",
       "    (attn): Linear(in_features=768, out_features=31, bias=True)\n",
       "    (attn_combine): Linear(in_features=768, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(model_name)\n",
    "model.eval()  # Important: set to eval mode before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_to_words(model, english_matrix_test, marathi_matrix_test, batch_size, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file \"predictions/uni_attn.csv\" has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# --- define data ---\n",
    "filename_test = 'predictions/uni_attn.csv'\n",
    "\n",
    "# english_words: list of English strings\n",
    "# predictions_vanilla_test: list of [actual_word, predicted_word] pairs\n",
    "\n",
    "\n",
    "\n",
    "# Combine into rows: [English, Actual, Predicted]\n",
    "rows = []\n",
    "for eng, (actual, predicted) in zip(english_words_test, predictions_vanilla_test):\n",
    "    rows.append([eng, actual, predicted])\n",
    "\n",
    "# --- write to CSV ---\n",
    "with open(filename_test, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['eng', 'actual', 'predicted'])  # header\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f'✅ CSV file \\\"{filename_test}\\\" has been created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file \"predictions/bi_no_attn.csv\" has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# --- define data ---\n",
    "filename_test = 'predictions/bi_no_attn.csv'\n",
    "\n",
    "# english_words: list of English strings\n",
    "# predictions_vanilla_test: list of [actual_word, predicted_word] pairs\n",
    "\n",
    "\n",
    "\n",
    "# Combine into rows: [English, Actual, Predicted]\n",
    "rows = []\n",
    "for eng, (actual, predicted) in zip(english_words_test, predictions_vanilla_test):\n",
    "    rows.append([eng, actual, predicted])\n",
    "\n",
    "# --- write to CSV ---\n",
    "with open(filename_test, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['eng', 'actual', 'predicted'])  # header\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f'✅ CSV file \\\"{filename_test}\\\" has been created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIS3GbEF5dsP",
    "outputId": "2f4b1594-3f7a-4502-f7e5-994c753b7a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"predictions_vanilla_test.csv\" has been created.\n"
     ]
    }
   ],
   "source": [
    "# creating csv file of predictions\n",
    "filename_test = 'bi_no_attn_predictions_vanilla_test.csv'\n",
    "\n",
    "with open(filename_test, 'w', newline='') as file:\n",
    "    writer = csv.writer(file, quoting=csv.QUOTE_NONE)\n",
    "    writer.writerows(predictions_vanilla_test)\n",
    "\n",
    "print(f'CSV file \"{filename_test}\" has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_accuracies(csv_path):\n",
    "    # Read CSV (no headers)\n",
    "    df = pd.read_csv(csv_path, header=None, sep=',', names=['actual', 'predicted'])\n",
    "    \n",
    "    # Drop any empty rows\n",
    "    df = df.dropna()\n",
    "    \n",
    "    total_words = len(df)\n",
    "    correct_words = 0\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        actual = str(row['actual']).strip()\n",
    "        predicted = str(row['predicted']).strip()\n",
    "\n",
    "        # --- Word-level accuracy ---\n",
    "        if actual == predicted:\n",
    "            correct_words += 1\n",
    "\n",
    "        # --- Character-level accuracy ---\n",
    "        max_len = max(len(actual), len(predicted))\n",
    "        total_chars += max_len\n",
    "        for a, b in zip(actual, predicted):\n",
    "            if a == b:\n",
    "                correct_chars += 1\n",
    "\n",
    "    word_acc = correct_words / total_words * 100 if total_words > 0 else 0\n",
    "    char_acc = correct_chars / total_chars * 100 if total_chars > 0 else 0\n",
    "\n",
    "    print(f\"✅ Word-level accuracy: {word_acc:.2f}%\")\n",
    "    print(f\"✅ Character-level accuracy: {char_acc:.2f}%\")\n",
    "\n",
    "    return word_acc, char_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "67svBk48GAaX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word-level accuracy: 39.45%\n",
      "✅ Character-level accuracy: 71.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39.453125, 71.55517656195276)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"predictions_vanilla_test.csv\"\n",
    "calculate_accuracies(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LyTr7QZKMqQG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = 'models/model_LSTM_bi_noattn.pt'\n",
    "# === 1. Load saved model ===\n",
    "model = torch.load(model_name, map_location=device)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded successfully\")\n",
    "\n",
    "# === 2. Helper function to convert English word to tensor ===\n",
    "def encode_word(word, lang_dict, max_len):\n",
    "    tensor = torch.zeros(max_len, dtype=torch.long)\n",
    "    for i, ch in enumerate(word):\n",
    "        if ch in lang_dict:\n",
    "            tensor[i] = lang_dict[ch] + 1\n",
    "        else:\n",
    "            tensor[i] = 0  # unknown char or padding\n",
    "    return tensor.unsqueeze(1).to(device)  # shape: (seq_len, 1)\n",
    "\n",
    "# === 3. Helper function to decode tensor back to Marathi string ===\n",
    "def decode_tensor(tensor, marathi_char_list):\n",
    "    word = \"\"\n",
    "    for idx in tensor:\n",
    "        if 0 < idx < len(marathi_char_list) + 1:\n",
    "            word += marathi_char_list[idx - 1]\n",
    "    return word\n",
    "\n",
    "# === 2. Predict for a single English word ===\n",
    "def predict_word(model, english_word):\n",
    "    # convert to numeric tensor using your own function\n",
    "    eng_vec = word2vec(english_word, \"english\")\n",
    "    inp_tensor = torch.tensor(eng_vec, dtype=torch.long).unsqueeze(1).to(device)  # shape [seq_len, 1]\n",
    "    \n",
    "    # dummy target tensor (zeroed out)\n",
    "    target_tensor = torch.zeros(max_length_word_marathi + 2, 1, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.forward(inp_tensor, target_tensor, 0)  # teacher forcing = 0\n",
    "        output = nn.Softmax(dim=2)(output)\n",
    "        output = torch.argmax(output, dim=2).squeeze(1)  # shape: [seq_len]\n",
    "    \n",
    "    # decode the predicted indices into Marathi characters\n",
    "    predicted_word = \"\"\n",
    "    for idx in output:\n",
    "        idx = idx.item()\n",
    "        if 0 < idx <= len(marathi_char_list):\n",
    "            predicted_word += marathi_char_list[idx - 1]\n",
    "    \n",
    "    return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1reXcQN1-xUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: kaustubh\n",
      "Predicted Marathi: कुस्तूभ\n"
     ]
    }
   ],
   "source": [
    "# === 5. Example usage ===\n",
    "english_word = \"kaustubh\"  # any test English transliteration\n",
    "predicted_marathi = predict_word(\n",
    "    model, \n",
    "    english_word\n",
    ")\n",
    "print(f\"English: {english_word}\")\n",
    "print(f\"Predicted Marathi: {predicted_marathi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMyJeinM-xUS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "d9sr6TtgPdmn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 10112/10112 [02:08<00:00, 78.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to bi_lstm_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Load the test CSV (no headers) ---\n",
    "original_csv = \"../../aks_dataset/hin/test.csv\"\n",
    "df_test = pd.read_csv(original_csv, header=None)\n",
    "\n",
    "# --- Give column names to df_test ---\n",
    "df_test.columns = ['eng', 'actual']  # first column = English, second column = reference Hindi\n",
    "\n",
    "# --- Setup device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Make sure your model is on the device\n",
    "model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# --- Predict function wrapper ---\n",
    "def predict_words_batch(model, words):\n",
    "    \"\"\"Predict multiple words using GPU.\"\"\"\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for word in tqdm(words):\n",
    "            word = str(word).strip()\n",
    "            pred = predict_word(model, word)  # your existing function\n",
    "            predictions.append(pred)\n",
    "    return predictions\n",
    "\n",
    "# --- Get first column (English words) ---\n",
    "first_column = df_test['eng'].tolist()\n",
    "\n",
    "# --- Run predictions ---\n",
    "predicted = predict_words_batch(model, first_column)\n",
    "\n",
    "# --- Save predictions back to DataFrame ---\n",
    "df_test['predicted'] = predicted\n",
    "\n",
    "# --- Save to CSV ---\n",
    "df_test.to_csv(\"bi_no_attn_lstm_predictions.csv\", index=False)\n",
    "print(\"Predictions saved to bi_lstm_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crRv0WD-Hu6V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyTr7QZKMqQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1reXcQN1-xUT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrNT-rKM-xUT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPoWLZG3-xUT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
